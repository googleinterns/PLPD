{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc83c31c",
   "metadata": {},
   "source": [
    "To try:\n",
    "turn off noise - 87% accuracy after one epoch (actually better than what I got for DPSGD, which is ~70% at best)\n",
    "regularizer only (no public) - gets ~75% after one epoch w/ no noise, ~63% with noise\n",
    "try adam\n",
    "larger public batches - similar performance w/o noise (87%), memory issues w/ opacus (should ask Shuang)\n",
    "without clipping if that's limitation\n",
    "linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b0bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91418f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from opacus.privacy_engine import PrivacyEngine\n",
    "from opacus.utils.tensor_utils import calc_sample_norms\n",
    "\n",
    "#devicestring = \"cpu\"\n",
    "devicestring = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(devicestring)\n",
    "print(\"Running on \"+devicestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6475e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Dataset loading\n",
    "publicratio = 1.0/100\n",
    "batch_size = 500\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))])\n",
    "#First get whole training set\n",
    "trainset = torchvision.datasets.MNIST(root = \"./data\", train=True, download=True, transform = transform)\n",
    "#Compute its size\n",
    "dataset_size = len(trainset)\n",
    "#Split into two based on dataset_size and publicratio\n",
    "publicset, privateset = torch.utils.data.random_split(trainset, [int(dataset_size*publicratio), dataset_size-int(dataset_size*publicratio)])\n",
    "#Public data only has one batch so we can compute full gradient\n",
    "publicloader = torch.utils.data.DataLoader(publicset, batch_size=int(dataset_size*publicratio), shuffle=True, num_workers=2)\n",
    "privateloader = torch.utils.data.DataLoader(privateset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e914d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "59400\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Check that the splitting procedure worked as desired\n",
    "print(len(publicset))\n",
    "print(len(privateset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc559d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST net used in DPSGD experiments\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=(2, 2))\n",
    "        self.pool1 = nn.MaxPool2d((2, 2), (1, 1))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=(2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2), (1, 1))\n",
    "        self.fc1 = nn.Linear(32*3*3, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.tanh(self.conv1(x)))\n",
    "        x = self.pool2(F.tanh(self.conv2(x)))\n",
    "        x = x.view(-1, 32*3*3)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(F.tanh(x))\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7493ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printaccuracy(model):\n",
    "    #Training accuracy computed wrt private data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in privateloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Training accuracy: %f %%' % (\n",
    "        100.0 * correct / total))\n",
    "    trainacc = 100.0 * correct / total\n",
    "\n",
    "    #Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Test accuracy: %f %%' % (\n",
    "        100.0 * correct / total))\n",
    "    testacc = 100.0 * correct / total\n",
    "    return trainacc, testacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dcadede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for pre-training on public data\n",
    "publicepochs = 1000\n",
    "publiceta = .001\n",
    "#Parameters for mirror descent\n",
    "privateepochs = 5\n",
    "privatesubepochs = 15\n",
    "privateeta = 1 #The multiplier in the mirror descent step; what eta would be if the public loss was l_2^2\n",
    "gradienteta = 1.0/max(privatesubepochs, 1) #The eta used in gradient descent to approximately apply the mirror descent step\n",
    "alpha = .01 #Multiplier for regularizer of public loss\n",
    "max_grad_norm = 1.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "PATH = \"./mirrorMNIST.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c389aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.440585565567017\n",
      "5.395879077911377\n",
      "5.417283725738526\n",
      "5.446928071975708\n",
      "5.486677646636963\n",
      "5.547674751281739\n",
      "5.685459613800049\n",
      "5.776526689529419\n",
      "5.904817533493042\n",
      "6.006949186325073\n",
      "6.205539798736573\n",
      "6.387717390060425\n",
      "6.582955837249756\n",
      "6.790817403793335\n",
      "7.017303562164307\n",
      "7.258028841018676\n",
      "7.425089979171752\n",
      "7.831024312973023\n",
      "7.949736118316651\n",
      "8.23702630996704\n",
      "8.30252161026001\n",
      "8.666950225830078\n",
      "8.657898616790773\n",
      "8.99028205871582\n",
      "9.251654529571534\n",
      "9.462717533111572\n",
      "9.58435640335083\n",
      "9.826332664489746\n",
      "10.078086566925048\n",
      "10.138338184356689\n",
      "10.266630935668946\n",
      "9.970556259155273\n",
      "10.782227516174316\n",
      "10.061916065216066\n",
      "10.664013957977296\n",
      "10.193002700805666\n",
      "10.653643798828131\n",
      "10.549207210540773\n",
      "10.745615196228027\n",
      "10.8653244972229\n",
      "10.817012691497805\n",
      "11.108688831329346\n",
      "10.988939189910889\n",
      "11.633142852783203\n",
      "11.050825214385986\n",
      "11.701076602935794\n",
      "11.192299461364748\n",
      "11.71213312149048\n",
      "11.573079204559328\n",
      "11.729810428619386\n",
      "11.72019557952881\n",
      "11.903264713287355\n",
      "12.162795734405517\n",
      "12.154720306396484\n",
      "12.267504596710207\n",
      "12.373622131347656\n",
      "12.586539268493654\n",
      "12.433535194396974\n",
      "12.708125400543214\n",
      "12.437200546264648\n",
      "12.86564359664917\n",
      "12.865015220642093\n",
      "12.946251392364502\n",
      "13.256072998046875\n",
      "13.030141544342044\n",
      "13.340515708923341\n",
      "13.395779037475588\n",
      "13.13403234481812\n",
      "13.383262634277347\n",
      "13.637706851959232\n",
      "13.606155204772955\n",
      "13.360531044006352\n",
      "13.746547985076907\n",
      "13.963732433319095\n",
      "14.024287223815923\n",
      "13.868020534515384\n",
      "13.373078441619876\n",
      "13.962971401214604\n",
      "13.840709495544434\n",
      "13.207668113708515\n",
      "13.9702956199646\n",
      "14.08855495452881\n",
      "13.948635768890389\n",
      "14.147263145446777\n",
      "13.61796588897705\n",
      "13.913710975646977\n",
      "14.376843643188478\n",
      "13.673881149292\n",
      "14.055762958526614\n",
      "13.997111988067628\n",
      "13.33464651107789\n",
      "13.396119022369387\n",
      "13.725570869445804\n",
      "13.173189258575444\n",
      "13.390692138671875\n",
      "13.270370578765872\n",
      "13.33864154815674\n",
      "12.878975200653077\n",
      "12.857952213287357\n",
      "12.56061935424806\n",
      "13.034682846069337\n",
      "12.962727260589599\n",
      "12.572049140930178\n",
      "12.811671638488772\n",
      "12.3097451210022\n",
      "12.376558303833008\n",
      "12.299616718292242\n",
      "11.791055870056153\n",
      "11.834815311431885\n",
      "11.088180541992193\n",
      "10.713447284698496\n",
      "11.314445972442627\n",
      "10.966117000579837\n",
      "11.510927486419678\n",
      "11.73888502120972\n",
      "10.872094058990482\n",
      "11.310713863372804\n",
      "10.542693614959717\n",
      "10.894072723388684\n",
      "Epoch 0\n",
      "Training accuracy: 90.388889 %\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 5, 5], expected input[500, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-797509437d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprintaccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccountant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_privacy_spent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epsilon: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\", Delta: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccountant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-4a219a6f08bb>\u001b[0m in \u001b[0;36mprintaccuracy\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-88cbde61e6d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 5, 5], expected input[500, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "#Benchmark: SGD on private data (from warm start / with public-based clipping)\n",
    "\n",
    "epochs = 5\n",
    "model = Net()\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1.0)\n",
    "accountant = PrivacyEngine(model, sample_rate = 1.0*batch_size/len(privateset), epochs = epochs,\n",
    "                           max_grad_norm = 1.0, noise_multiplier = 1.0, target_delta = .00001)\n",
    "accountant.attach(optimizer)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(privateloader, 0):\n",
    "        for ipub, datapub in enumerate(publicloader, 0):\n",
    "            model.zero_grad()\n",
    "            images, labels = datapub[0].to(device), datapub[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            oldpubgrad = [param.grad.clone() for param in list(model.parameters())]\n",
    "            all_norms = calc_sample_norms(accountant.clipper._named_grad_samples(),\n",
    "                                          flat = not accountant.clipper.norm_clipper.is_per_layer,)\n",
    "            batchmaxnorm = np.percentile(np.array(all_norms[0].tolist()), 90)\n",
    "            print(batchmaxnorm)\n",
    "#             accountant.clipper.norm_clipper.flat_value = batchmaxnorm\n",
    "#             accountant.max_grad_norm = batchmaxnorm\n",
    "            \n",
    "        model.zero_grad()\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        reg = 0.0\n",
    "        for param in model.parameters():\n",
    "            reg += 0.5 * (param ** 2).sum()\n",
    "        loss = criterion(outputs, labels) + alpha * reg / 2.0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch \"+str(epoch))\n",
    "    printaccuracy(model)\n",
    "    eps, _ = accountant.get_privacy_spent()\n",
    "    print(\"Epsilon: \"+str(eps)+\", Delta: \"+str(accountant.target_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "publicoptimizer = optim.SGD(model.parameters(), lr = publiceta)\n",
    "\n",
    "#Pre-train with public data\n",
    "for epoch in range(publicepochs):\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch)\n",
    "    for i, data in enumerate(publicloader, 0):\n",
    "        model.zero_grad()\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        reg = 0.0\n",
    "        for param in model.parameters():\n",
    "            reg += 0.5 * (param ** 2).sum()\n",
    "        loss = criterion(outputs, labels) + alpha * reg / 2.0\n",
    "        loss.backward()\n",
    "        publicoptimizer.step()\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23f3641c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model:\n",
      "Training accuracy: 10.294613 %\n",
      "Test accuracy: 10.490000 %\n",
      "5.033283042907715\n",
      "5.061603212356568    \n",
      "5.424864864349365    \n",
      "6.049815893173219    \n",
      "6.904062271118164    \n",
      "7.658203506469727    \n",
      "8.338461780548096    \n",
      "8.945199871063233    \n",
      "9.412149715423583    \n",
      "9.706239700317385    \n",
      "9.792721366882326     \n",
      "9.773414325714114     \n",
      "9.753943347930909     \n",
      "9.556483936309817     \n",
      "9.327620792388917     \n",
      "8.990334606170654     \n",
      "8.626467037200928     \n",
      "8.329613494873048     \n",
      "7.8722510814666755    \n",
      "7.633558940887453     \n",
      "7.26455240249634      \n",
      "6.913193464279176     \n",
      "6.600597095489503     \n",
      "6.280859661102296     \n",
      "6.040863609313965     \n",
      "5.839288949966431     \n",
      "5.664372158050537     \n",
      "5.415504980087281     \n",
      "5.195626354217531     \n",
      "5.08429651260376      \n",
      "4.9632229804992685    \n",
      "4.7866282939910905    \n",
      "4.731948184967041     \n",
      "4.595897579193116     \n",
      "4.469481468200686     \n",
      "4.34823899269104      \n",
      "4.264409017562889     \n",
      "4.16892666816716      \n",
      "4.128041791915908     \n",
      "4.088994503021249     \n",
      "4.036056327819829     \n",
      "3.9853679895401       \n",
      "3.894784283638001     \n",
      "3.833039641380321     \n",
      "3.764748716354391     \n",
      "3.7631350755691564    \n",
      "3.762068390846253     \n",
      "3.6762478351593053    \n",
      "3.5892923116683972    \n",
      "3.5769607067108153    \n",
      "3.5554967880249024    \n",
      "3.53951096534729      \n",
      "3.5129857778549205    \n",
      "3.4664538621902494    \n",
      "3.422285223007217     \n",
      "3.394413065910351     \n",
      "3.389485120773319     \n",
      "3.3738543510437013    \n",
      "3.3737023115158093    \n",
      "3.3638685941696167    \n",
      "3.3534828186035255    \n",
      "3.3281284332275396    \n",
      "3.3114884614944464    \n",
      "3.3134606599807768    \n",
      "3.308097624778748     \n",
      "3.3013635635375977    \n",
      "3.2636447906494195    \n",
      "3.1837378501892433    \n",
      "3.1739266157150468    \n",
      "3.178266692161579     \n",
      "3.2181131124496516    \n",
      "3.216125631332398     \n",
      "3.1739545106887825    \n",
      "3.1368389368057326    \n",
      "3.1420005798339843    \n",
      "3.133806943893433     \n",
      "3.126878190040595     \n",
      "3.1062592029571565    \n",
      "3.1265472888946535    \n",
      "3.125651001930238     \n",
      "3.1089358329772967    \n",
      "3.099814414978035     \n",
      "3.0962002992630007    \n",
      "3.0912195205688477    \n",
      "3.085903811454777     \n",
      "3.082433366775514     \n",
      "3.049919152259843     \n",
      "3.006205582618746     \n",
      "2.9979608058929808    \n",
      "2.995396661758462     \n",
      "2.987881731987045     \n",
      "2.9780643463135243    \n",
      "2.962262797355696     \n",
      "2.972227072715797     \n",
      "2.971261787414587     \n",
      "2.9514441013336628    \n",
      "2.919383668899604     \n",
      "2.936251544952449     \n",
      "2.9749006509781286    \n",
      "2.966839456558254     \n",
      "2.9595213174820243     \n",
      "2.9320899248123666     \n",
      "2.8739316701889646     \n",
      "2.923783850669898      \n",
      "2.902103495597876      \n",
      "2.9649638414382937     \n",
      "2.9616031646728516     \n",
      "2.927271509170533      \n",
      "2.900009846687317      \n",
      "2.89481921195984       \n",
      "2.873582291603091      \n",
      "2.8478538990020885     \n",
      "2.8437793254852455     \n",
      "2.8253432273864796     \n",
      "2.802935147285477      \n",
      "2.8000554084778044     \n",
      "2.7879994153976724     \n",
      "2.777381896972677      \n",
      "2.7640099048614557     \n",
      "Epoch 1                    \n",
      "Time taken:563.7676892280579\n",
      "Training accuracy: 93.867003 %\n",
      "Test accuracy: 94.680000 %\n",
      "Epsilon: 1.5283554086281967, Delta: 1e-05\n",
      "2.752171707153331\n",
      "2.7564526557922573   \n",
      "2.7613719463348767   \n",
      "2.7642916917801266   \n",
      "2.7594780921936284   \n",
      "2.763112163543724    \n",
      "2.7720613479614347   \n",
      "2.773205161094679    \n",
      "2.7745800495147916   \n",
      "2.7751104831695788   \n",
      "2.7472668647766527    \n",
      "2.7483015537262343    \n",
      "2.769055128097561     \n",
      "2.76717903614047      \n",
      "2.765751910209668     \n",
      "2.7601873636245795    \n",
      "16/119 14/15          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ed34ad4dc617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m#Store gradient of new regularized public loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprivateset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprivatesubepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"          \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mipub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublicloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatapub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                     \u001b[0;31m# wrong, we set a timeout and if the workers fail to join,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;31m# they are killed in the `finally` block.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "#model.load_state_dict(torch.load(PATH)) #Toggle this to load warm start\n",
    "model = model.to(device)\n",
    "privateoptimizer = optim.SGD(model.parameters(), lr = 0.0)\n",
    "accountant = PrivacyEngine(model, sample_rate = 1.0*batch_size/len(privateset), epochs = privateepochs,\n",
    "                            max_grad_norm = 100.0, noise_multiplier = 1.0, target_delta = .00001)\n",
    "accountant.attach(privateoptimizer)\n",
    "mdoptimizer = optim.SGD(model.parameters(), lr = gradienteta)\n",
    "#mdoptimizer = optim.Adam(model.parameters(), lr = .001)\n",
    "\n",
    "def regularizer(model):\n",
    "    reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        reg += 0.5 * (param ** 2).sum()\n",
    "    return alpha*reg\n",
    "    \n",
    "\n",
    "#Training accuracy computed wrt private data\n",
    "print(\"Initial model:\")\n",
    "printaccuracy(model)\n",
    "    \n",
    "for epoch in range(privateepochs):\n",
    "    starttime = time.time()\n",
    "    for i, data in enumerate(privateloader, 0):\n",
    "        #Store old gradient of regularizer\n",
    "        model.zero_grad()\n",
    "        loss = regularizer(model)\n",
    "        loss.backward()\n",
    "        oldreggrad = [param.grad.clone() for param in list(model.parameters())]\n",
    "                \n",
    "        #Store gradient of old regularized public loss\n",
    "        for ipub, datapub in enumerate(publicloader, 0):\n",
    "            model.zero_grad()\n",
    "            images, labels = datapub[0].to(device), datapub[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) + regularizer(model)\n",
    "            loss.backward()\n",
    "            oldpubgrad = [param.grad.clone() for param in list(model.parameters())]\n",
    "            all_norms = calc_sample_norms(accountant.clipper._named_grad_samples(),\n",
    "                                          flat = not accountant.clipper.norm_clipper.is_per_layer,)\n",
    "            batchmaxnorm = np.percentile(np.array(all_norms[0].tolist()), 90)\n",
    "            accountant.clipper.norm_clipper.flat_value = batchmaxnorm\n",
    "            accountant.max_grad_norm = batchmaxnorm\n",
    "        print(batchmaxnorm)\n",
    "        \n",
    "        #Store gradient of private loss in privgrad\n",
    "        model.zero_grad()\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        #Compute the norm to use for clipping\n",
    "        \n",
    "        #Clip and add noise, also do first gradient step\n",
    "        privateoptimizer.step()\n",
    "        privgrad = [param.grad.clone() for param in list(model.parameters())] #Storing the clipped, noisy gradient\n",
    "\n",
    "        for subepoch in range(privatesubepochs):\n",
    "            #Store new gradient of regularizer\n",
    "            model.zero_grad()\n",
    "            loss = regularizer(model)\n",
    "            loss.backward()\n",
    "            newreggrad = [param.grad.clone() for param in list(model.parameters())]\n",
    "            \n",
    "            #Store gradient of new regularized public loss\n",
    "            print(str(i+1)+\"/\"+str(1+int(len(privateset)/batch_size))+\" \"+str(subepoch+1)+\"/\"+str(privatesubepochs)+\"          \", end=\"\\r\")\n",
    "            for ipub, datapub in enumerate(publicloader, 0):\n",
    "                model.zero_grad()\n",
    "                images, labels = datapub[0].to(device), datapub[1].to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) + regularizer(model)\n",
    "                loss.backward()\n",
    "            #Manually compute l_2 norm of public gradient \n",
    "            j = 0\n",
    "            normsquared = 0.0\n",
    "            for param in model.parameters():\n",
    "                normsquared += ((param.grad.clone() - oldpubgrad[j])**2).sum()\n",
    "                j += 1\n",
    "            norm = normsquared ** 0.5\n",
    "            #scale = min(1.0, max_grad_norm/norm) #Toggle this and next line to disable/enable public gradient scaling\n",
    "            scale = 1.0\n",
    "            #Accumulate the mirror descent gradient\n",
    "            j = 0\n",
    "            for param in model.parameters():\n",
    "                mirrorgrad = (param.grad.clone() - oldpubgrad[j])*scale+newreggrad[j]-oldreggrad[j]+privgrad[j]*privateeta\n",
    "                param.grad = mirrorgrad\n",
    "                j += 1\n",
    "            mdoptimizer.step()\n",
    "    \n",
    "    endtime = time.time()\n",
    "    #Print training/test accuracy\n",
    "    print(\"Epoch \"+str(epoch+1)+\"                    \")\n",
    "    print(\"Time taken:\"+str(endtime-starttime))\n",
    "    printaccuracy(model)\n",
    "    eps, _ = accountant.get_privacy_spent()\n",
    "    print(\"Epsilon: \"+str(eps)+\", Delta: \"+str(accountant.target_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d3dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
